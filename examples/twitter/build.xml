<?xml version="1.0" ?>
<project default="default" name="twitter build file">

<property name="TwitterUsername" value="Set_to_your_username"/>
<property name="TwitterPassword" value="Set_to_your_password"/>
<property name="hdfs.path" value="/user/${user.name}/twitter" />
<property name="hadoop" value="${user.home}/hadoop/bin/hadoop" />
<property name="jar" value="unique-user-count.jar" />

<import file="../includes/basebuild.xml"/>

<path id='project.classpath'>
    <fileset dir='../../voltdb' >
        <include name='voltdb*.jar' />
    </fileset>
    <pathelement location='${build.dir}' />
    <pathelement path="${java.class.path}"/>
    <fileset refid="additional.classpath"/>
    <fileset id="additional.classpath" dir='.' >
      <include name='twitter4j-core-*.jar' />
      <include name="hadoop-*-core.jar" />
      <include name="commons-logging-api-*.jar" />
    </fileset>
</path>

<target name="client" description="Start the tweet processing client">
    <invoke-java classname="org.voltdb.twitter.drivers.Trends" >
        <jvmarg value="-Dtwitter4j.loggerFactory=twitter4j.internal.logging.StdOutLoggerFactory" />
        <arg value="${TwitterUsername}"/>               <!-- twitter login username -->
        <arg value="${TwitterPassword}"/>               <!-- twitter login password -->
        <arg value="12345" />                           <!-- port to listen to for web server -->
        <arg value="20" />                              <!-- number of hashtags to show in each table -->
        <arg value="localhost" />                       <!-- comma separated list of volt servers to connect to -->
    </invoke-java>
</target>

<target name="cull" depends="srccompile" description="Start the cull background process to discard old tweets" >
    <invoke-java classname="org.voltdb.twitter.drivers.Cull" >
        <jvmarg value="-Dtwitter4j.loggerFactory=twitter4j.internal.logging.StdOutLoggerFactory" />
        <arg value="4" />                                   <!-- how long to retain tweets for (in hours) -->
        <arg value="1" />                                   <!-- how often to cull tweets (in hours) -->
        <arg value="localhost" />                           <!-- comma separated list of volt servers to connect to -->
    </invoke-java>
</target>

<target name="hadoop-el" description="Start the EL client.">
    <exec executable="${hadoop}" failonerror="false">
        <arg line="fs" />
        <arg line="-rmr" />
        <arg value="-skipTrash" />
        <arg value="${hdfs.path}" />
    </exec>
    <invoke-java classname="org.voltdb.twitter.hadoop.hdfs.ExportToHDFSClient">
        <arg value="${hdfs.path}/input" />
        <arg value="localhost" />
    </invoke-java>
</target>
    
<!-- could be refactored to only include the relevant classes -->
<target name="hadoop-jar" depends="srccompile" description="Compile the JAR to be used by Hadoop.">
    <jar destfile="${jar}" basedir="obj">
        <manifest>
            <attribute name="Main-Class" value="org.voltdb.twitter.hadoop.mr.JobRunner" />
        </manifest>
    </jar>
</target>

<target name="hadoop-mr" depends="hadoop-jar" description="Run the MapReduce job.">
    <exec executable="${hadoop}" failonerror="false">
        <arg line="fs" />
        <arg line="-rmr" />
        <arg value="-skipTrash" />
        <arg value="${hdfs.path}/tmp" />
    </exec>
    <exec executable="${hadoop}" failonerror="false">
        <arg line="fs" />
        <arg line="-rmr" />
        <arg value="-skipTrash" />
        <arg value="${hdfs.path}/output" />
    </exec>
    <exec executable="${hadoop}" failonerror="true">
        <arg line="jar ${jar}" />
        <arg line="-D mapred.reduce.tasks=1" />
        <arg value="${hdfs.path}" />
    </exec>
</target>

</project>
